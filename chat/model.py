from typing import Any, List, Literal, NotRequired, TypedDict
from pydantic import BaseModel, Field
from config import settings

class ToolCall(TypedDict):
    """Represents a request to call a tool."""

    name: str
    """The name of the tool to be called."""
    args: dict[str, Any]
    """The arguments to the tool call."""
    id: str | None
    """An identifier associated with the tool call."""
    type: NotRequired[Literal["tool_call"]]
    
class ChatMessage(BaseModel):
    """Message in a chat."""

    type: Literal["human", "ai", "tool", "custom"] = Field(
        description="Role of the message.",
        examples=["human", "ai", "tool", "custom"],
    )
    content: str = Field(
        description="Content of the message.",
        examples=["Hello, world!"],
    )
    tool_calls: list[ToolCall] = Field(
        description="Tool calls in the message.",
        default=[],
    )
    tool_call_id: str | None = Field(
        description="Tool call that this message is responding to.",
        default=None,
        examples=["call_Jja7J89XsjrOLA5r!MEOW!SL"],
    )
    run_id: str | None = Field(
        description="Run ID of the message.",
        default=None,
        examples=["847c6285-8fc9-4560-a83f-4e6285809254"],
    )
    response_metadata: dict[str, Any] = Field(
        description="Response metadata. For example: response headers, logprobs, token counts.",
        default={},
    )
    usage_metadata: dict[str, Any] = Field(
        description="Usage metadata. For example: response headers, logprobs, token counts.",
        default={},
    )
    metadata: List[Any] = Field(
        description="Response metadata. For example: prompt tokens, cached tokens, total tokens",
        default=[]
    )
    custom_data: dict[str, Any] = Field(
        description="Custom message data.",
        default={},
    )
    thread_id: str | None = Field(
        description="Thread id of the session.",
        default=None,
        examples=["847c6285-8fc9-4560-a83f-4e6285809254"],
    )

    def pretty_repr(self) -> str:
        """Get a pretty representation of the message."""
        base_title = self.type.title() + " Message"
        padded = " " + base_title + " "
        sep_len = (80 - len(padded)) // 2
        sep = "=" * sep_len
        second_sep = sep + "=" if len(padded) % 2 else sep
        title = f"{sep}{padded}{second_sep}"
        return f"{title}\n\n{self.content}"

    def pretty_print(self) -> None:
        print(self.pretty_repr())  # noqa: T201

class ChatInput(BaseModel):
    thread_id: str | None = Field(
        description="Optional thread ID associated with the chat session. Used to track conversations across multiple interactions.",
        default=None,
        examples=["847c6285-8fc9-4560-a83f-4e6285809254"],
    )
    model: str = Field(
        description="The model to use for the chat. This should be a valid model identifier.",
        examples=["gemini-2.5-flash"],
        default=settings.DEFAULT_MODEL
    )
    temperature: float = Field(
        default=settings.DEFAULT_TEMPERATURE,
        description="Controls randomness: 0.0 (deterministic) to 1.0 (creative).",
    )
    prompt: str = Field(
        description="The system prompt or context that will be used to guide the model's responses.",
        default=None,
    )
    query: str = Field(
        description="The user's query or prompt that will be sent to the model.",
    )
    stream: bool = Field(
        default=False
    )
    
class ChatResponse(BaseModel):
    thread_id: str | None = Field(
        description="Optional thread ID associated with the chat session. Used to track conversations across multiple interactions.",
        default=None,
        examples=["847c6285-8fc9-4560-a83f-4e6285809254"],
    )
    run_id: str | None = Field(
        description="Optional run ID associated with the message. Used to track messages across a thread.",
        default=None,
        examples=["847c6285-8fc9-4560-a83f-4e6285809254"],
    )
    query: str = Field(
        description="The user's query or prompt that was sent to the model. This is the input message for which a response is generated.",
        examples=["How is the weather today?", "Tell me a joke."],
        default=""
    )
    reply: str = Field(
        description="The model's response to the user's query. This is the output message generated by the model based on the input query.",
        examples=["The weather today is sunny with a high of 75Â°F.", "Why did the scarecrow win an award? Because he was outstanding in his field!"],
        default=""
    )